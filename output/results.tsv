Model	Pretraining	Input length	Classifier head	Classifier head -  hidden layers	Embedding strategy	Fine-tuning	LoRA rank	Learning rate	Training Sample size	Batch size	Num steps	Grad accum	Best Validation AUC	Training time (hr)	Training memory (GB)	Trainable params	All params	Training_Step1000_AUC	Training_Step2000_AUC	Training_Step3000_AUC	Training_Step4000_AUC	Training_Step5000_AUC	Training_Step6000_AUC	Training_Step7000_AUC	Training_Step8000_AUC	Training_Step9000_AUC	Training_Step10000_AUC	Val_Step1000_AUC	Val_Step2000_AUC	Val_Step3000_AUC	Val_Step4000_AUC	Val_Step5000_AUC	Val_Step6000_AUC	Val_Step7000_AUC	Val_Step8000_AUC	Val_Step9000_AUC	Val_Step10000_AUC
NT-2	multi-species	12000	mlp	2	variant_position	frozen	n/a	3.00E-05	44k	32	5000	n/a	0.869		26.96			0.802474	0.852409	0.867718	0.876077	0.882754						0.824371	0.857746	0.863736	0.869147	0.868001					
NT-2	multi-species	12000	mlp	2	mean_pool	frozen	n/a	3.00E-05	44k	32	5000	n/a	0.751		26.96			0.671026	0.705205	0.716484	0.729517	0.735303						0.696792	0.72887	0.744182	0.748942	0.751304					
NT-2	multi-species	12000	mlp	3	variant_position	frozen	n/a	3.00E-05	44k	32	5000	n/a	0.869		26.96			0.816995	0.85935	0.874374	0.882799	0.890641						0.835026	0.857835	0.865584	0.868191	0.869278					
NT-2	multi-species	12000	transformer	2	variant_position	frozen	n/a	3.00E-05	44k	32	5000	n/a	0.869		26.96			0.832201	0.858101	0.866398	0.871263	0.874156						0.846645	0.860897	0.865427	0.866214	0.868673					
NT-2	multi-species	12000	transformer	2	mean_pool	frozen	n/a	3.00E-05	44k	32	5000	n/a	0.775		26.96			0.718107	0.757337	0.767547	0.773837	0.777748						0.737239	0.769571	0.775326	0.769926	0.774622					
NT-2	multi-species	12000	cnn	2	mean_pool	frozen	n/a	3.00E-05	44k	32	5000	n/a	0.778		26.96			0.748177	0.769942	0.78442	0.789721	0.790297						0.743713	0.770441	0.772617	0.773949	0.778419					
NT-2	multi-species	12000	cnn	2	variant_position	frozen	n/a	3.00E-05	44k	32	5000	n/a	0.871		26.96			0.865243	0.897642	0.914263	0.926942	0.932297						0.850003	0.866624	0.868943	0.870221	0.870587					
NT-2	multi-species	12000	cnn	2	variant_position	unfreeze all	n/a	3.00E-05	44k	8	10000	"n/a (Note: smaller batch size adds more regularization compared to larger ones, so if overfitting is observed for smaller batch size, it must also occur with larger batch size (i.e., unnecessary to rerun with gradient accumulation)"	0.788					0.542427	0.689888	0.747427	0.778991	0.821281	0.857581	0.879288	0.904097	0.918657	0.933591	0.545107	0.669008	0.717647	0.718805	0.754563	0.770628	0.777026	0.7874	0.780714	0.788363
NT-2	multi-species	6000	cnn	2	variant_position	frozen-input_leng=6k	n/a	3.00E-05	44k	32	5000	n/a	0.8638	54.86				0.8582	0.8867	0.9069	0.9187	0.9216						0.8458	0.8538	0.862	0.8638	0.863					
NT-2	multi-species	12000	cnn	2	variant_position	lora	8	3.00E-05	5k	4	4000	n/a	0.8345	7.45	51.32	"950,272"	"499,295,708"	0.888851511	0.944315479	0.963995747	0.970995918							0.825929916	0.829607862	0.834484507	0.833861395						
NT-2	multi-species	12000	cnn	2	variant_position	lora	16	3.00E-05	5k	4	4000	n/a	0.8376	7.51	51.34	"1,900,544"	"500,245,980"	0.889126354	0.948864201	0.970093671	0.974666468							0.821161523	0.837639672	0.833594724	0.83433929						
NT-2	multi-species	12000	cnn	2	variant_position	lora	32	3.00E-05	5k	4	4000	n/a	0.8453	7.38	51.39	"3,801,088"	"502,146,524"	0.904919073	0.946360885	0.97071542	0.978838392							0.838933422	0.839638384	0.845280717	0.840306381						
NT-2	multi-species	12000	cnn	2	variant_position	lora	32	3.00E-05	44k	4	40000	8	0.8861					0.816880467	0.876351766	0.900986597	0.920753628	0.935164478	0.948877688	0.960495155				0.831203821	0.861646369	0.879910397	0.881882775	0.88613358	0.883301153	0.883821978			
NT-2	multi-species	12000	cnn	2	variant_position	lora	32	5.00E-05	44k	4	40000	8	0.8856					0.847832196	0.887306911	0.917438284	0.936705212	0.953770339						0.850399816	0.867550345	0.885592703	0.877505655	0.882440755					
NT-2	multi-species	12000	cnn	2	variant_position	lora	32	1.00E-05	44k	4	40000	8	0.8793					0.723465473	0.844088967	0.870299117	0.886724248	0.897233827	0.907902788	0.916527992	0.924706052			0.75120655	0.851640624	0.86777678	0.869266255	0.876815497	0.879255247	0.878711909	0.87880442		
NT-1	human	6000	cnn	2	variant_position	frozen	n/a	3.00E-05	44k	32	5000	n/a	0.7322	20.08	11.44	"1,082,625"	"486,781,931"	0.763158465	0.811775122	0.846941168	0.867487202	0.874842148						0.71302309	0.720174383	0.728930787	0.731747892	0.732176712					
Caduceus	ps	30000	mlp	2	variant_position	frozen	n/a	3.00E-05	44k				0.596876					0.55985	0.571537	0.583238	0.590673	0.592883						0.562172	0.572935	0.585433	0.594192	0.596876					
Caduceus	ps	30000	mlp	2	mean_pool	frozen	n/a	3.00E-05	44k				0.45918					0.503636	0.511276	0.515953	0.517857	0.518273						0.418828	0.425983	0.447244	0.456483	0.45918					
Caduceus	ps	30000	mlp	3	variant_position	frozen	n/a	3.00E-05	44k				0.599565					0.555408	0.56819	0.583763	0.593157	0.595689						0.558054	0.568203	0.588144	0.596646	0.599565					
Caduceus	ps	30000	cnn	2	downsample-mean_pool	frozen	n/a	3.00E-05	44k				0.670923					0.639095	0.656813	0.664906	0.669088	0.673532						0.646376	0.632065	0.670923	0.66009	0.663363					
Caduceus	ps	30000	transformer	2	downsample-mean_pool	frozen	n/a	3.00E-05	44k				0.560211					0.533209	0.537374	0.54542	0.545414	0.547435						0.554395	0.552011	0.560211	0.555263	0.555948					
Caduceus	ps	30000	cnn	2	downsample-variant_position	frozen	n/a	3.00E-05	44k				0.753605					0.700191	0.724365	0.737687	0.743271	0.745841						0.715466	0.741093	0.744898	0.753122	0.753605					
Caduceus	ps	30000	transformer	2	downsample-variant_position	frozen	n/a	3.00E-05	44k				0.700477					0.639159	0.658031	0.666589	0.670834	0.672107						0.68164	0.692392	0.697454	0.697558	0.700477					